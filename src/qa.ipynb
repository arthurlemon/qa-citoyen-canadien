{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from haystack import Pipeline, Document\n",
    "from haystack.utils import Secret\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever, InMemoryEmbeddingRetriever\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.components.builders.answer_builder import AnswerBuilder\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack.components.converters import PyPDFToDocument\n",
    "from haystack.components.preprocessors import DocumentCleaner, DocumentSplitter\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.embedders import OpenAIDocumentEmbedder, OpenAITextEmbedder\n",
    "from langfuse.decorators import observe, langfuse_context\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x127d397d0>\n",
       "üöÖ Components\n",
       "  - retriever: InMemoryBM25Retriever\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: OpenAIGenerator\n",
       "üõ§Ô∏è Connections\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> llm.prompt (str)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write documents to InMemoryDocumentStore\n",
    "document_store = InMemoryDocumentStore()\n",
    "document_store.write_documents([\n",
    "    Document(content=\"My name is Jean and I live in Paris.\"), \n",
    "    Document(content=\"My name is Mark and I live in Berlin.\"), \n",
    "    Document(content=\"My name is Giorgio and I live in Rome.\")\n",
    "])\n",
    "\n",
    "# Build a RAG pipeline\n",
    "prompt_template = \"\"\"\n",
    "Given these documents, answer the question.\n",
    "Documents:\n",
    "{% for doc in documents %}\n",
    "    {{ doc.content }}\n",
    "{% endfor %}\n",
    "Question: {{question}}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "retriever = InMemoryBM25Retriever(document_store=document_store)\n",
    "prompt_builder = PromptBuilder(template=prompt_template)\n",
    "llm = OpenAIGenerator(model=\"gpt-4o-mini\", api_key=Secret.from_token(os.getenv(\"OPENAI_API_KEY\")))\n",
    "\n",
    "rag_pipeline = Pipeline()\n",
    "rag_pipeline.add_component(\"retriever\", retriever)\n",
    "rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "rag_pipeline.add_component(\"llm\", llm)\n",
    "rag_pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "rag_pipeline.connect(\"prompt_builder\", \"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@observe(as_type=\"generation\")\n",
    "def ask_question(question:str) -> str:\n",
    "    results = rag_pipeline.run(\n",
    "        {\n",
    "            \"retriever\": {\"query\": question},\n",
    "            \"prompt_builder\": {\"question\": question},\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return (results[\"llm\"][\"replies\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jean lives in Paris.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_question(\"Who lives in Paris?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x128833d90>\n",
       "üöÖ Components\n",
       "  - converter: PyPDFToDocument\n",
       "  - cleaner: DocumentCleaner\n",
       "  - splitter: DocumentSplitter\n",
       "  - embedder: OpenAIDocumentEmbedder\n",
       "  - writer: DocumentWriter\n",
       "üõ§Ô∏è Connections\n",
       "  - converter.documents -> cleaner.documents (List[Document])\n",
       "  - cleaner.documents -> splitter.documents (List[Document])\n",
       "  - splitter.documents -> embedder.documents (List[Document])\n",
       "  - embedder.documents -> writer.documents (List[Document])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "preprocessing_pipeline = Pipeline()\n",
    "preprocessing_pipeline.add_component(\"converter\", PyPDFToDocument())\n",
    "preprocessing_pipeline.add_component(\"cleaner\", DocumentCleaner())\n",
    "preprocessing_pipeline.add_component(\"splitter\", DocumentSplitter(split_by=\"sentence\", split_length=5))\n",
    "preprocessing_pipeline.add_component(\"embedder\", OpenAIDocumentEmbedder())\n",
    "preprocessing_pipeline.add_component(\"writer\", DocumentWriter(document_store=document_store))\n",
    "preprocessing_pipeline.connect(\"converter\", \"cleaner\")\n",
    "preprocessing_pipeline.connect(\"cleaner\", \"splitter\")\n",
    "preprocessing_pipeline.connect(\"splitter\", \"embedder\")\n",
    "preprocessing_pipeline.connect(\"embedder\", \"writer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@observe()\n",
    "def ingest_pdf(pipeline, pdf_path: str) -> None:\n",
    "    pipeline.run({\"converter\": {\"sources\": [pdf_path]}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 54/54 [00:26<00:00,  2.07it/s]\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"../data/decouvrir.pdf\"\n",
    "ingest_pdf(preprocessing_pipeline, pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x1289ef790>\n",
       "üöÖ Components\n",
       "  - embedder: OpenAITextEmbedder\n",
       "  - retriever: InMemoryEmbeddingRetriever\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - generation: OpenAIGenerator\n",
       "üõ§Ô∏è Connections\n",
       "  - embedder.embedding -> retriever.query_embedding (List[float])\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> generation.prompt (str)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Answer the questions based on the given context.\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{ question }}\n",
    "Answer:\n",
    "\"\"\"\n",
    "inference_pipeline = Pipeline()\n",
    "inference_pipeline.add_component(\"embedder\", OpenAITextEmbedder())\n",
    "inference_pipeline.add_component(\"retriever\", InMemoryEmbeddingRetriever(document_store=document_store))\n",
    "inference_pipeline.add_component(\"prompt_builder\", PromptBuilder(template=template))\n",
    "inference_pipeline.add_component(\n",
    "    \"generation\",\n",
    "    OpenAIGenerator(model=\"gpt-4o\"),\n",
    ")\n",
    "\n",
    "inference_pipeline.connect(\"embedder.embedding\", \"retriever.query_embedding\")\n",
    "inference_pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "inference_pipeline.connect(\"prompt_builder\", \"generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@observe(as_type=\"generation\")\n",
    "def ask_question_pdf(question: str):\n",
    "    langfuse_context.update_current_observation(\n",
    "      input=question\n",
    "  )\n",
    " \n",
    "    response = inference_pipeline.run(\n",
    "        {\n",
    "            \"embedder\": {\"text\": question},\n",
    "            \"prompt_builder\": {\"question\": question},\n",
    "            \"generation\": {\"generation_kwargs\": {\"max_tokens\": 500}},\n",
    "        }\n",
    ")\n",
    "    langfuse_context.update_current_observation(\n",
    "        model= response[\"generation\"][\"meta\"][0][\"model\"],\n",
    "      usage={\n",
    "          \"input\": response[\"generation\"][\"meta\"][0][\"usage\"][\"prompt_tokens\"],\n",
    "          \"output\": response[\"generation\"][\"meta\"][0][\"usage\"][\"total_tokens\"]\n",
    "      }\n",
    "  )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ask_question_pdf(\"Quelles sont les diff√©rentes sections du document ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
